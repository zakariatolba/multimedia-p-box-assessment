{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Traning Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPD6OeoYQDRkUpaLj8bZ72a"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zdL4pDovjmx"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "!kill 275\n",
        "from datetime import datetime\n",
        "from packaging import version\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from numpy import zeros,array\n",
        "\n",
        "import sys\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import cv2 as cv\n",
        "\n",
        "#import tensorflow_addons as tfa\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "import csv\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path1=\"/content/drive/My Drive/P-Box-Black-box-assasement/Datasets/Fashion Mnist/\"\n",
        "path2=\"/content/drive/My Drive/P-Box-Black-box-assasement/Datasets/Mnist/\"\n",
        "\n",
        "%tensorboard --logdir logs\n",
        "\n",
        "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "root_logdir = os.path.join(os.curdir, \"logs\\\\fit\\\\\")\n",
        "\n",
        "\n",
        "# importion Ciphered data set for training and test\n",
        "\n",
        "x_train = np.loadtxt(path2+'One round GCBPM.txt')\n",
        "\n",
        "x_train = x_train.reshape((60000,28,28))\n",
        "\n",
        "\n",
        "x_test = np.loadtxt(path2+'One round GCBPMTest.txt')\n",
        "\n",
        "x_test = x_test.reshape((10000,28,28))\n",
        "\n",
        "# importion Plain data set for training and test\n",
        "\n",
        "y_train = np.loadtxt(path+'MnistTrain.txt')\n",
        "\n",
        "y_train = y_train.reshape((60000,28,28))\n",
        "\n",
        "\n",
        "y_test = np.loadtxt(path+'MnistTest.txt')\n",
        "\n",
        "y_test = y_test.reshape((10000,28,28))\n",
        "\n",
        "x_train.shape\n",
        "\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0],28,28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28,28, 1)\n",
        "y_train = y_train.reshape(y_train.shape[0],28,28, 1)\n",
        "y_test = y_test.reshape(y_test.shape[0],28,28, 1)\n",
        "input_shape = (28, 28,1)\n",
        "# Making sure that the values are float so that we can get decimal points after division\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "y_train = y_train.astype('float32')\n",
        "y_test = y_test.astype('float32')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Importing the required Keras modules containing model and layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "model = tf.keras.models.load_model('/content/drive/My Drive/P-Box-Black-box-assasement/Model/')\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "#-----------------------------------------------------------------------------\n",
        "# Define custom loss functions for regression in Keras \n",
        "#-----------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "# mean squared error (mse) for regression\n",
        "def mse(y_true, y_pred):\n",
        "    from keras import backend\n",
        "    return backend.mean(backend.square(y_pred - y_true), axis=-1)\n",
        "\n",
        "# coefficient of determination (R^2) for regression\n",
        "def r_square(y_true, y_pred):\n",
        "    from keras import backend as K\n",
        "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
        "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
        "    return (1 - SS_res/(SS_tot + K.epsilon()))\n",
        "\n",
        "def r_square_loss(y_true, y_pred):\n",
        "    from keras import backend as K\n",
        "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
        "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
        "    return 1 - ( 1 - SS_res/(SS_tot + K.epsilon()))\n",
        "def quantile_loss(q, y, y_p):\n",
        "        e = y-y_p\n",
        "        return tf.keras.backend.mean(tf.keras.backend.maximum(q*e, (q-1)*e))        \n",
        "quantile =0.5\n",
        "\n",
        "\n",
        "\n",
        "model.compile(optimizer=\"Adam\", loss=lambda y, y_p: quantile_loss(quantile, y, y_p),metrics=[r_square,\"mean_squared_error\"])\n",
        "\n",
        "filepath = \"/content/drive/My Drive/P-Box-Black-box-assasement/weights/One round GCBPM.hdf5\"\n",
        "\n",
        "metric = 'loss'\n",
        "EPOCHS=1500\n",
        "cp_callback =tf.keras.callbacks.ModelCheckpoint(filepath, monitor=metric, verbose=2, save_best_only=True,mode='auto')\n",
        "\n",
        "\n",
        "start_lr = 0.1\n",
        "min_lr = 0.00001\n",
        "max_lr = 0.00005 * 8\n",
        "#max_lr = 0.00005 * tpu_strategy.num_replicas_in_sync\n",
        "rampup_epochs = 10\n",
        "sustain_epochs = 0\n",
        "exp_decay = .8\n",
        "\n",
        "def lrfn(epoch):\n",
        "  if epoch < rampup_epochs:\n",
        "    return (max_lr - start_lr)/rampup_epochs * epoch + start_lr\n",
        "  elif epoch < rampup_epochs + sustain_epochs:\n",
        "    return max_lr\n",
        "  else:\n",
        "    return (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n",
        "    \n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=True)\n",
        "\n",
        "rang = np.arange(EPOCHS)\n",
        "y = [lrfn(x) for x in rang]\n",
        "plt.plot(rang, y)\n",
        "print('Learning rate per epoch:')\n",
        "\n",
        "\n",
        "training_dataset=(x_train,y_train)\n",
        "validation_dataset=(x_test,y_test)\n",
        "train_steps = 60000 // 2000\n",
        "\n",
        "from datetime import datetime\n",
        "from packaging import version\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorboard\n",
        "%reload_ext tensorboard\n",
        "\n",
        "\n",
        "\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=root_logdir,histogram_freq=1)\n",
        "\n",
        "history =model.fit(x=x_train,y=y_train, validation_data=(x_test,y_test), epochs=EPOCHS,batch_size=2000, verbose=1,steps_per_epoch=train_steps,\n",
        "                   callbacks=[lr_callback,cp_callback,tensorboard_callback])\n",
        "\n",
        "\n",
        "import sklearn.metrics, math\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def display_training_curves(training, validation, title, subplot):\n",
        "  ax = plt.subplot(subplot)\n",
        "  ax.plot(training)\n",
        "  ax.plot(validation)\n",
        "  ax.set_title('model '+ title)\n",
        "  ax.set_ylabel(title)\n",
        "  ax.set_xlabel('epoch')\n",
        "  ax.legend(['training', 'validation'])\n",
        "\n",
        "plt.subplots(figsize=(20,20))\n",
        "plt.tight_layout()\n",
        "display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'accuracy', 211)\n",
        "display_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 212)\n",
        "\n",
        "\n"
      ]
    }
  ]
}